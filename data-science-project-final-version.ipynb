{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Import Required Libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.special import boxcox1p\nfrom scipy.stats import skew\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries imported successfully!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:15:49.648855Z","iopub.execute_input":"2025-11-17T14:15:49.649121Z","iopub.status.idle":"2025-11-17T14:15:59.686592Z","shell.execute_reply.started":"2025-11-17T14:15:49.649094Z","shell.execute_reply":"2025-11-17T14:15:59.685582Z"}},"outputs":[{"name":"stdout","text":"Libraries imported successfully!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Load Data\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Test shape: {test.shape}\")\nprint(f\"\\nFirst few rows of train data:\")\nprint(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:16:12.046715Z","iopub.execute_input":"2025-11-17T14:16:12.047007Z","iopub.status.idle":"2025-11-17T14:16:12.125499Z","shell.execute_reply.started":"2025-11-17T14:16:12.046984Z","shell.execute_reply":"2025-11-17T14:16:12.124719Z"}},"outputs":[{"name":"stdout","text":"Train shape: (1460, 81)\nTest shape: (1459, 80)\n\nFirst few rows of train data:\n   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n\n  YrSold  SaleType  SaleCondition  SalePrice  \n0   2008        WD         Normal     208500  \n1   2007        WD         Normal     181500  \n2   2008        WD         Normal     223500  \n3   2006        WD        Abnorml     140000  \n4   2008        WD         Normal     250000  \n\n[5 rows x 81 columns]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 3: Save Test IDs and Remove Outliers\ntest_ID = test['Id']\n\n# Remove outliers (recommended in competition description)\nprint(f\"Before removing outliers: {train.shape}\")\ntrain = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\nprint(f\"After removing outliers: {train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:16:15.542538Z","iopub.execute_input":"2025-11-17T14:16:15.542815Z","iopub.status.idle":"2025-11-17T14:16:15.553653Z","shell.execute_reply.started":"2025-11-17T14:16:15.542795Z","shell.execute_reply":"2025-11-17T14:16:15.552958Z"}},"outputs":[{"name":"stdout","text":"Before removing outliers: (1460, 81)\nAfter removing outliers: (1458, 81)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 4: Log Transform Target Variable\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\ny_train = train['SalePrice'].values\n\ntrain.drop(['Id', 'SalePrice'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)\n\nprint(f\"Target variable (log-transformed) shape: {y_train.shape}\")\nprint(f\"Train features shape: {train.shape}\")\nprint(f\"Test features shape: {test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:17:49.783082Z","iopub.execute_input":"2025-11-17T14:17:49.783964Z","iopub.status.idle":"2025-11-17T14:17:49.799457Z","shell.execute_reply.started":"2025-11-17T14:17:49.783936Z","shell.execute_reply":"2025-11-17T14:17:49.798732Z"}},"outputs":[{"name":"stdout","text":"Target variable (log-transformed) shape: (1458,)\nTrain features shape: (1458, 79)\nTest features shape: (1459, 79)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 5: Feature Engineering Function\ndef engineer_features(df):\n    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n    df['TotalBath'] = (df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n    df['TotalPorchSF'] = (df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF'])\n    df['HasPool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n    df['Has2ndFloor'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n    df['HasGarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n    df['HasBsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n    df['HasFireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n    df['OverallGrade'] = df['OverallQual'] * df['OverallCond']\n    df['QualGrLiv'] = df['OverallQual'] * df['GrLivArea']\n    df['QualBsmt'] = df['OverallQual'] * df['TotalBsmtSF']\n    df['QualGarage'] = df['OverallQual'] * df['GarageArea']\n    df['QualPorch'] = df['OverallQual'] * df['TotalPorchSF']\n    df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n    df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']\n    df['GarageAge'] = df['YrSold'] - df['GarageYrBlt']\n    df['IsRemodeled'] = (df['YearRemodAdd'] != df['YearBuilt']).astype(int)\n    df['IsNewHouse'] = (df['YearBuilt'] == df['YrSold']).astype(int)\n    df['SimplOverallQual'] = df['OverallQual'].replace({1: 1, 2: 1, 3: 1, 4: 2, 5: 2, 6: 2, 7: 3, 8: 3, 9: 3, 10: 3})\n    df['SimplExterQual'] = df['ExterQual'].replace({'Po': 1, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4})\n    df['SimplKitchenQual'] = df['KitchenQual'].replace({'Po': 1, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4})\n    df['SimplBsmtQual'] = df['BsmtQual'].replace({'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n    df['SimplGarageQual'] = df['GarageQual'].replace({'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n    df['SimplHeatingQC'] = df['HeatingQC'].replace({'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n    return df\n\nprint(\"Feature engineering function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:18:17.960964Z","iopub.execute_input":"2025-11-17T14:18:17.961303Z","iopub.status.idle":"2025-11-17T14:18:17.973634Z","shell.execute_reply.started":"2025-11-17T14:18:17.961281Z","shell.execute_reply":"2025-11-17T14:18:17.972672Z"}},"outputs":[{"name":"stdout","text":"Feature engineering function defined!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 6: Missing Values Handling Function\ndef handle_missing_values(df):\n    none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType']\n    for col in none_cols:\n        if col in df.columns:\n            df[col].fillna('None', inplace=True)\n    zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']\n    for col in zero_cols:\n        if col in df.columns:\n            df[col].fillna(0, inplace=True)\n    if 'LotFrontage' in df.columns:\n        if 'Neighborhood' in df.columns:\n            df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n        else:\n            df['LotFrontage'].fillna(df['LotFrontage'].median(), inplace=True)\n    for col in df.columns:\n        if df[col].isnull().sum() > 0:\n            if df[col].dtype == 'object':\n                df[col].fillna(df[col].mode()[0], inplace=True)\n            else:\n                df[col].fillna(df[col].median(), inplace=True)\n    return df\n\nprint(\"Missing values handling function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:21:54.969101Z","iopub.execute_input":"2025-11-17T14:21:54.969501Z","iopub.status.idle":"2025-11-17T14:21:54.977764Z","shell.execute_reply.started":"2025-11-17T14:21:54.969476Z","shell.execute_reply":"2025-11-17T14:21:54.976846Z"}},"outputs":[{"name":"stdout","text":"Missing values handling function defined!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 7: Feature Encoding Function\ndef encode_features(df):\n    ordinal_mappings = {\n        'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n        'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n        'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n        'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'FireplaceQu': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n        'PoolQC': {'None': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n        'Fence': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n    }\n    for col, mapping in ordinal_mappings.items():\n        if col in df.columns:\n            df[col] = df[col].map(mapping)\n    df = pd.get_dummies(df, drop_first=True)\n    return df\n\nprint(\"Feature encoding function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:22:18.352564Z","iopub.execute_input":"2025-11-17T14:22:18.353200Z","iopub.status.idle":"2025-11-17T14:22:18.361794Z","shell.execute_reply.started":"2025-11-17T14:22:18.353170Z","shell.execute_reply":"2025-11-17T14:22:18.360928Z"}},"outputs":[{"name":"stdout","text":"Feature encoding function defined!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 8: Fix Skewness Function\ndef fix_skewness(df, threshold=0.75):\n    # Get numeric columns only\n    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n    # Remove binary columns\n    numeric_cols = [col for col in numeric_cols if df[col].nunique() > 2]\n    if len(numeric_cols) == 0:\n        print(\"No numeric features to fix skewness\")\n        return df\n    # Calculate skewness safely\n    skewness_dict = {}\n    for col in numeric_cols:\n        try:\n            col_skew = skew(df[col].dropna())\n            if not np.isnan(col_skew) and not np.isinf(col_skew):\n                skewness_dict[col] = col_skew\n        except:\n            continue\n    if not skewness_dict:\n        print(\"Could not calculate skewness for any features\")\n        return df\n    skewness = pd.DataFrame({'Skew': skewness_dict}).sort_values(by='Skew', ascending=False)\n    skewness = skewness[abs(skewness['Skew']) > threshold]\n    print(f\"Number of skewed features (|skew| > {threshold}): {len(skewness)}\")\n    lam = 0.15\n    for feat in skewness.index:\n        try:\n            df[feat] = boxcox1p(df[feat], lam)\n        except:\n            continue\n    return df\n\nprint(\"Skewness fixing function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:22:55.664357Z","iopub.execute_input":"2025-11-17T14:22:55.665048Z","iopub.status.idle":"2025-11-17T14:22:55.672234Z","shell.execute_reply.started":"2025-11-17T14:22:55.665021Z","shell.execute_reply":"2025-11-17T14:22:55.671525Z"}},"outputs":[{"name":"stdout","text":"Skewness fixing function defined!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell 9: Apply All Preprocessing Steps\nprint(\"Step 1: Handling Missing Values FIRST...\")\ntrain = handle_missing_values(train)\ntest = handle_missing_values(test)\nprint(\"Missing values handled!\")\n\nprint(\"\\nStep 2: Feature Engineering...\")\ntrain = engineer_features(train)\ntest = engineer_features(test)\nprint(f\"Train shape after feature engineering: {train.shape}\")\n\nprint(\"\\nStep 3: Encoding Features...\")\nntrain = train.shape[0]\nntest = test.shape[0]\nall_data = pd.concat((train, test)).reset_index(drop=True)\nprint(f\"Combined data shape: {all_data.shape}\")\nall_data = encode_features(all_data)\nprint(f\"After encoding: {all_data.shape}\")\n\nprint(\"\\nStep 4: Fixing Skewness...\")\nall_data = fix_skewness(all_data)\n\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]\n\nprint(\"\\nStep 5: Final NaN check and filling...\")\nprint(f\"Train NaN count: {train.isnull().sum().sum()}\")\nprint(f\"Test NaN count: {test.isnull().sum().sum()}\")\nif train.isnull().sum().sum() > 0 or test.isnull().sum().sum() > 0:\n    print(\"Filling remaining NaN values with 0...\")\n    train = train.fillna(0)\n    test = test.fillna(0)\nprint(f\"\\nFinal train shape: {train.shape}\")\nprint(f\"Final test shape: {test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:23:24.841635Z","iopub.execute_input":"2025-11-17T14:23:24.842226Z","iopub.status.idle":"2025-11-17T14:23:25.192808Z","shell.execute_reply.started":"2025-11-17T14:23:24.842200Z","shell.execute_reply":"2025-11-17T14:23:25.192139Z"}},"outputs":[{"name":"stdout","text":"Step 1: Handling Missing Values FIRST...\nMissing values handled!\n\nStep 2: Feature Engineering...\nTrain shape after feature engineering: (1458, 103)\n\nStep 3: Encoding Features...\nCombined data shape: (2917, 103)\nAfter encoding: (2917, 243)\n\nStep 4: Fixing Skewness...\nNumber of skewed features (|skew| > 0.75): 39\n\nStep 5: Final NaN check and filling...\nTrain NaN count: 0\nTest NaN count: 1\nFilling remaining NaN values with 0...\n\nFinal train shape: (1458, 243)\nFinal test shape: (1459, 243)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Cell 10: Scale Features\nscaler = RobustScaler()\nX_train = scaler.fit_transform(train)\nX_test = scaler.transform(test)\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(\"\\nData is ready for modeling!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:23:43.439773Z","iopub.execute_input":"2025-11-17T14:23:43.440326Z","iopub.status.idle":"2025-11-17T14:23:43.547041Z","shell.execute_reply.started":"2025-11-17T14:23:43.440300Z","shell.execute_reply":"2025-11-17T14:23:43.546206Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (1458, 243)\nX_test shape: (1459, 243)\ny_train shape: (1458,)\n\nData is ready for modeling!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Cell 11: Stacking Model Classes\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        for model in self.models_:\n            model.fit(X, y)\n        return self\n    def predict(self, X):\n        predictions = np.column_stack([model.predict(X) for model in self.models_])\n        return np.mean(predictions, axis=1)\n\nclass StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n    def predict(self, X):\n        meta_features = np.column_stack([np.column_stack([model.predict(X) for model in base_models]).mean(axis=1) for base_models in self.base_models_])\n        return self.meta_model_.predict(meta_features)\n\nprint(\"Stacking model classes defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:24:17.671534Z","iopub.execute_input":"2025-11-17T14:24:17.672346Z","iopub.status.idle":"2025-11-17T14:24:17.682080Z","shell.execute_reply.started":"2025-11-17T14:24:17.672322Z","shell.execute_reply":"2025-11-17T14:24:17.681344Z"}},"outputs":[{"name":"stdout","text":"Stacking model classes defined!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Cell 12: Define Base Models\nprint(\"Defining models...\")\nlasso = Lasso(alpha=0.0005, random_state=42, max_iter=10000)\nridge = Ridge(alpha=10, random_state=42)\nelasticnet = ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=42, max_iter=10000)\ngbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=42)\nxgboost = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=2200, reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213, random_state=42, n_jobs=-1)\nlightgbm = lgb.LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.05, n_estimators=720, max_bin=55, bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2319, feature_fraction_seed=9, bagging_seed=9, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, random_state=42, verbose=-1)\nprint(\"All models defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:24:42.866523Z","iopub.execute_input":"2025-11-17T14:24:42.866808Z","iopub.status.idle":"2025-11-17T14:24:42.873899Z","shell.execute_reply.started":"2025-11-17T14:24:42.866788Z","shell.execute_reply":"2025-11-17T14:24:42.873202Z"}},"outputs":[{"name":"stdout","text":"Defining models...\nAll models defined!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Cell 13: Create Stacked Model\nprint(\"Creating stacked model...\")\nstacked_averaged_models = StackingAveragedModels(base_models=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm), meta_model=ridge)\nprint(\"Stacked model created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:24:59.207684Z","iopub.execute_input":"2025-11-17T14:24:59.208331Z","iopub.status.idle":"2025-11-17T14:24:59.212724Z","shell.execute_reply.started":"2025-11-17T14:24:59.208305Z","shell.execute_reply":"2025-11-17T14:24:59.211927Z"}},"outputs":[{"name":"stdout","text":"Creating stacked model...\nStacked model created!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Cell 14: Train Stacked Model (This will take several minutes)\nprint(\"Training stacked model...\")\nprint(\"This may take 5-10 minutes...\\n\")\nstacked_averaged_models.fit(X_train, y_train)\nprint(\"Stacked model training completed!\\n\")\nstacked_train_pred = stacked_averaged_models.predict(X_train)\nstacked_pred = stacked_averaged_models.predict(X_test)\nstacked_rmse = np.sqrt(mean_squared_error(y_train, stacked_train_pred))\nprint(f\"Stacked Model Training RMSE: {stacked_rmse:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:25:13.305594Z","iopub.execute_input":"2025-11-17T14:25:13.306341Z","iopub.status.idle":"2025-11-17T14:26:26.332413Z","shell.execute_reply.started":"2025-11-17T14:25:13.306317Z","shell.execute_reply":"2025-11-17T14:26:26.331677Z"}},"outputs":[{"name":"stdout","text":"Training stacked model...\nThis may take 5-10 minutes...\n\nStacked model training completed!\n\nStacked Model Training RMSE: 0.08189\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Cell 15: Train XGBoost Model\nprint(\"Training XGBoost model...\")\nxgboost.fit(X_train, y_train)\nxgb_train_pred = xgboost.predict(X_train)\nxgb_pred = xgboost.predict(X_test)\nxgb_rmse = np.sqrt(mean_squared_error(y_train, xgb_train_pred))\nprint(f\"XGBoost Training RMSE: {xgb_rmse:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:28:31.125053Z","iopub.execute_input":"2025-11-17T14:28:31.125965Z","iopub.status.idle":"2025-11-17T14:28:35.019348Z","shell.execute_reply.started":"2025-11-17T14:28:31.125934Z","shell.execute_reply":"2025-11-17T14:28:35.018791Z"}},"outputs":[{"name":"stdout","text":"Training XGBoost model...\nXGBoost Training RMSE: 0.08501\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Cell 16: Train LightGBM Model\nprint(\"Training LightGBM model...\")\nlightgbm.fit(X_train, y_train)\nlgb_train_pred = lightgbm.predict(X_train)\nlgb_pred = lightgbm.predict(X_test)\nlgb_rmse = np.sqrt(mean_squared_error(y_train, lgb_train_pred))\nprint(f\"LightGBM Training RMSE: {lgb_rmse:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:28:38.683642Z","iopub.execute_input":"2025-11-17T14:28:38.684666Z","iopub.status.idle":"2025-11-17T14:28:39.268313Z","shell.execute_reply.started":"2025-11-17T14:28:38.684639Z","shell.execute_reply":"2025-11-17T14:28:39.267372Z"}},"outputs":[{"name":"stdout","text":"Training LightGBM model...\nLightGBM Training RMSE: 0.06917\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Cell 17: Create Ensemble Predictions and Submission\nprint(\"Creating ensemble predictions...\")\nensemble_pred = stacked_pred * 0.70 + xgb_pred * 0.15 + lgb_pred * 0.15\nensemble_pred = np.expm1(ensemble_pred)\nsubmission = pd.DataFrame({'Id': test_ID, 'SalePrice': ensemble_pred})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"✓ Submission file created: submission.csv\")\nprint(f\"✓ Total predictions: {len(submission)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:28:42.775867Z","iopub.execute_input":"2025-11-17T14:28:42.776195Z","iopub.status.idle":"2025-11-17T14:28:42.797365Z","shell.execute_reply.started":"2025-11-17T14:28:42.776169Z","shell.execute_reply":"2025-11-17T14:28:42.796476Z"}},"outputs":[{"name":"stdout","text":"Creating ensemble predictions...\n✓ Submission file created: submission.csv\n✓ Total predictions: 1459\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Cell 18: Summary\nprint(\"=\" * 60)\nprint(\"FINAL MODEL SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"\\nTraining RMSE Scores:\")\nprint(f\"  Stacked Model: {stacked_rmse:.5f}\")\nprint(f\"  XGBoost:       {xgb_rmse:.5f}\")\nprint(f\"  LightGBM:      {lgb_rmse:.5f}\")\nprint(f\"\\nExpected Kaggle Score: ~0.10 - 0.115\")\nprint(\"=\" * 60)\nprint(submission.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:28:48.972450Z","iopub.execute_input":"2025-11-17T14:28:48.972748Z","iopub.status.idle":"2025-11-17T14:28:48.979779Z","shell.execute_reply.started":"2025-11-17T14:28:48.972726Z","shell.execute_reply":"2025-11-17T14:28:48.978959Z"}},"outputs":[{"name":"stdout","text":"============================================================\nFINAL MODEL SUMMARY\n============================================================\n\nTraining RMSE Scores:\n  Stacked Model: 0.08189\n  XGBoost:       0.08501\n  LightGBM:      0.06917\n\nExpected Kaggle Score: ~0.10 - 0.115\n============================================================\n     Id      SalePrice\n0  1461  121307.690609\n1  1462  159905.288276\n2  1463  180975.959669\n3  1464  195776.685999\n4  1465  190247.389224\n5  1466  171904.316137\n6  1467  176145.425293\n7  1468  163604.639984\n8  1469  189707.971461\n9  1470  122646.580007\n","output_type":"stream"}],"execution_count":20}]}